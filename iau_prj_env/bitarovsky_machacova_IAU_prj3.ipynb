{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03800150-2d8f-4045-a693-1d21b59e804d",
   "metadata": {},
   "source": [
    "# IAU projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4c4ea-39f7-4166-95e3-e8f91e4d949f",
   "metadata": {},
   "source": [
    "> Rovnakým podieľom práce vypracovali: <br>\n",
    "> Roman Bitarovský, Emma Macháčová"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391929a1",
   "metadata": {},
   "source": [
    "## Table of contents <a name=\"obsah\"></a>\n",
    "* [Zadanie](#zadanie)\n",
    "    * [Slovníček](#slovnicek)\n",
    "   \n",
    "* [Data init (Fáza 1)](#dataInit)\n",
    "* [Fáza 2](#faza2)\n",
    "    * [2.1. Integrácia a čistenie dát](#2.1.)\n",
    "        * [2.1.1. Replacing NaNs](#2.1.1.)\n",
    "            * [2.1.1.1. Replacing NaNs - Method 1: Drop nans](#2.1.1.a)\n",
    "            * [2.1.1.2. Replacing NaNs - Method 2: Replace with Mean](#2.1.1.b)\n",
    "            * [2.1.1.3. Replacing NaNs - Method 3: Replace with Median](#2.1.1.c)\n",
    "            * [2.1.1.4. Replacing NaNs - Method 4: Replace with kNN](#2.1.1.d)\n",
    "        * [2.1.2. Deleting Outliers Values](#2.1.2.)\n",
    "    * [2.2. Realizácia predspracovania dát](#2.2.)  \n",
    "        * [2.2.1. Transforovanie a škálovanie dát](#2.2.1.)\n",
    "        * [2.2.2. Rozdelenie dát](#2.2.2.)\n",
    "        * [2.2.3. Zhodnotenie ](#2.2.3.)\n",
    "    * [2.3. Výber atribútov pre strojové učenie](#2.3.)  \n",
    "        * [2.3.1. Variance Threshold ](#2.3.1.)\n",
    "        * [2.3.2. SelectKBest](#2.3.2.)\n",
    "        * [2.3.3 SelectPercentile](#2.3.3.)\n",
    "        * [2.3.4. Záver výberov](#2.3.4.)\n",
    "    * [2.4. Replikovateľnosť predspracovania](#2.4.)  \n",
    "        * [2.4.1. Code improvements](#2.4.1.)\n",
    "        * [2.4.2. Pipeline](#2.4.2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb7b2a",
   "metadata": {},
   "source": [
    "# Zadanie <a name=\"zadanie\"></a>\n",
    "Znečistenie ovzdušia spôsobuje vážne dýchacie a srdcové ochorenia, ktoré môžu byť smrteľné. Najčastejšie sú postihnuté deti, čo vedie k zápalu pľúc a problémom s dýchaním vrátane astmy. Kyslé dažde, ničenie ozónovej vrstvy a globálne otepľovanie sú niektoré z nepriaznivých dôsledkov. Dátová sada pre Vás (World's Air Pollution: Real-time Air Quality Index https://waqi.info/) predstavuje záznamy jednotlivých meraní kvality ovzdušia ako kombinácia mnohých faktorov bez časovej následnosti. V záznamoch je závislá premenná s menom “warning” indikujúca alarmujúci stav kvality ovzdušia. Vo veľkých mestách ako napr. Peking (angl. Beijing, hlavné mesto Číny s viac ako 21 miliónov ľudí) sa pri varovaní spustí opatrenie ako obmedzenie pohybov áut a ľudí v meste alebo umelý dážď až pokiaľ kvalita vzduchu sa nevráti do normu.\n",
    "\n",
    "* Úlohou je predikovať závislé hodnoty premennej “warning” pomocou metód strojového učenia.\n",
    "* Pritom sa treba vysporiadať s viacerými problémami, ktoré sa v dátach nachádzajú ako formáty dát, chýbajúce, vychýlené hodnoty a pod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca932d7e",
   "metadata": {},
   "source": [
    "## Slovníček  <a name=\"slovnicek\"></a>\n",
    "<details>\n",
    "    <summary>Zobraziť</summary>\n",
    "    \n",
    "    PM2.5 - Particulate Matter (µg/m3) \n",
    "    PM10 - Particulate Matter (µg/m3) \n",
    "    NOx - Nitrogen Oxides (µg/m3)\n",
    "    NO2 - Nitrogen Dioxide (µg/m3)\n",
    "    SO2 - Sulfur Dioxide  (µg/m3)\n",
    "    CO - Carbon Monoxide emissions  (µg/m3)\n",
    "    CO2 - Carbon Dioxide  (µg/m3)\n",
    "    PAHs - Polycyclic Aromatic Hydrocarbons  (µg/m3)\n",
    "    NH3 - Ammonia trace  (µg/m3)\n",
    "    Pb - Lead  (µg/m3)\n",
    "    TEMP - Temperature (degree Celsius)\n",
    "    DEWP - Dew point temperature (degree Celsius)\n",
    "    PRES - Pressure (hPa, <100, 1050>)\n",
    "    RAIN - Rain (mm)\n",
    "    WSPM - Wind Speed (m/s)\n",
    "    WD - Wind Direction\n",
    "    VOC - Volatile Organic Compounds\n",
    "    CFCs - Chlorofluorocarbons\n",
    "    C2H3NO5 - Peroxyacetyl nitrate\n",
    "    H2CO - Plywood emit formaldehyde\n",
    "    GSTM1 - Glutathione-S transferase M1\n",
    "    1-OHP - 1-hydroxypyrene\n",
    "    2-OHF - 2-hydroxyfluorene\n",
    "    2-OHNa - 2-hydroxynaphthalene\n",
    "    N2 - Nitrogen\n",
    "    O2 - Oxygen\n",
    "    O3 - Ozone\n",
    "    Ar - Argon\n",
    "    Ne - Neon\n",
    "    CH4 - Methane\n",
    "    He - Helium\n",
    "    Kr - Krypton\n",
    "    I2 - Iodine\n",
    "    H2 - Hydrogen\n",
    "    Xe - Xenon\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344e4ef-bf7a-4a03-9614-b6f3f23fa673",
   "metadata": {},
   "source": [
    "# Data init <a name=\"dataInit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3283a09-1bbb-4c16-9a19-e162077e5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.stats as sm_stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import f_oneway\n",
    "import datetime\n",
    "import re\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from numpy import percentile\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression, chi2, f_regression, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22d4502-5363-424b-bc0b-7defa57eda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_measurements = pd.read_csv('../081/measurements.csv', sep='\\t')\n",
    "labor_stations = pd.read_csv('../081/stations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a18289d-66a4-4ec4-86b7-81e7d62602c5",
   "metadata": {},
   "source": [
    "Úprava dát rovnaká ako vo fáze 1, hlavne teda merge tabuliek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa77e3ec-c960-411d-846b-20b5e3ae3d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>warning</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NOx</th>\n",
       "      <th>PM10</th>\n",
       "      <th>C2H3NO5</th>\n",
       "      <th>CH4</th>\n",
       "      <th>Pb</th>\n",
       "      <th>NH3</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>CO</th>\n",
       "      <th>PAHs</th>\n",
       "      <th>H2CO</th>\n",
       "      <th>CFCs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.05101</td>\n",
       "      <td>1139.12673</td>\n",
       "      <td>8.47714</td>\n",
       "      <td>9.21522</td>\n",
       "      <td>9.38738</td>\n",
       "      <td>1.51791</td>\n",
       "      <td>7.84989</td>\n",
       "      <td>59.51096</td>\n",
       "      <td>10.43604</td>\n",
       "      <td>5.81201</td>\n",
       "      <td>7.77502</td>\n",
       "      <td>9.69678</td>\n",
       "      <td>8.62090</td>\n",
       "      <td>47.64810</td>\n",
       "      <td>74.87342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.55701</td>\n",
       "      <td>1115.19699</td>\n",
       "      <td>7.36880</td>\n",
       "      <td>9.66741</td>\n",
       "      <td>8.19826</td>\n",
       "      <td>0.64236</td>\n",
       "      <td>8.48027</td>\n",
       "      <td>54.03980</td>\n",
       "      <td>9.62838</td>\n",
       "      <td>7.97135</td>\n",
       "      <td>9.72566</td>\n",
       "      <td>5.83821</td>\n",
       "      <td>8.28391</td>\n",
       "      <td>64.99154</td>\n",
       "      <td>63.42154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.06998</td>\n",
       "      <td>1086.02547</td>\n",
       "      <td>9.81855</td>\n",
       "      <td>9.66138</td>\n",
       "      <td>6.16989</td>\n",
       "      <td>0.23616</td>\n",
       "      <td>8.49506</td>\n",
       "      <td>47.32216</td>\n",
       "      <td>6.38848</td>\n",
       "      <td>6.14333</td>\n",
       "      <td>9.73098</td>\n",
       "      <td>7.37730</td>\n",
       "      <td>5.98279</td>\n",
       "      <td>43.12537</td>\n",
       "      <td>71.61779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.04558</td>\n",
       "      <td>1168.02340</td>\n",
       "      <td>8.76470</td>\n",
       "      <td>10.27526</td>\n",
       "      <td>7.10130</td>\n",
       "      <td>0.17080</td>\n",
       "      <td>7.35744</td>\n",
       "      <td>48.49527</td>\n",
       "      <td>8.11869</td>\n",
       "      <td>6.74522</td>\n",
       "      <td>9.63330</td>\n",
       "      <td>4.89810</td>\n",
       "      <td>8.76285</td>\n",
       "      <td>43.67037</td>\n",
       "      <td>64.64020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.88676</td>\n",
       "      <td>1061.95581</td>\n",
       "      <td>6.76710</td>\n",
       "      <td>9.95663</td>\n",
       "      <td>8.35517</td>\n",
       "      <td>0.75765</td>\n",
       "      <td>6.98671</td>\n",
       "      <td>52.91472</td>\n",
       "      <td>8.87397</td>\n",
       "      <td>9.24788</td>\n",
       "      <td>8.40595</td>\n",
       "      <td>10.82485</td>\n",
       "      <td>7.88543</td>\n",
       "      <td>40.39068</td>\n",
       "      <td>70.46390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              location  warning      TEMP        PRES    PM2.5       NOx  \\\n",
       "0  America/Los_Angeles      0.0  20.05101  1139.12673  8.47714   9.21522   \n",
       "1  America/Los_Angeles      1.0  21.55701  1115.19699  7.36880   9.66741   \n",
       "2  America/Los_Angeles      1.0   3.06998  1086.02547  9.81855   9.66138   \n",
       "3  America/Los_Angeles      1.0  10.04558  1168.02340  8.76470  10.27526   \n",
       "4  America/Los_Angeles      1.0  24.88676  1061.95581  6.76710   9.95663   \n",
       "\n",
       "      PM10  C2H3NO5      CH4        Pb       NH3      SO2       O3        CO  \\\n",
       "0  9.38738  1.51791  7.84989  59.51096  10.43604  5.81201  7.77502   9.69678   \n",
       "1  8.19826  0.64236  8.48027  54.03980   9.62838  7.97135  9.72566   5.83821   \n",
       "2  6.16989  0.23616  8.49506  47.32216   6.38848  6.14333  9.73098   7.37730   \n",
       "3  7.10130  0.17080  7.35744  48.49527   8.11869  6.74522  9.63330   4.89810   \n",
       "4  8.35517  0.75765  6.98671  52.91472   8.87397  9.24788  8.40595  10.82485   \n",
       "\n",
       "      PAHs      H2CO      CFCs  \n",
       "0  8.62090  47.64810  74.87342  \n",
       "1  8.28391  64.99154  63.42154  \n",
       "2  5.98279  43.12537  71.61779  \n",
       "3  8.76285  43.67037  64.64020  \n",
       "4  7.88543  40.39068  70.46390  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labor_stations[\"QoS\"].replace({\"acceptable\": \"accep\", \"maitennce\": \"maintenance\"}, inplace=True)\n",
    "labor_stations['revision'] = pd.to_datetime(labor_stations['revision'], utc=False)\n",
    "\n",
    "labor_measurements.replace('', np.nan, inplace=True)\n",
    "labor_measurements.replace(r'^\\s*$', np.nan, regex=True)\n",
    "labor_stations.replace('', np.nan, inplace=True)\n",
    "labor_stations.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "labor_measurements = labor_measurements.drop_duplicates()\n",
    "labor_stations = labor_stations.drop_duplicates()\n",
    "\n",
    "# merge preprocesing\n",
    "labor_stations = labor_stations.drop(columns=['revision', 'code', 'QoS'])\n",
    "labor_stations = labor_stations.drop_duplicates()\n",
    "\n",
    "# Table merge\n",
    "df = pd.merge(labor_measurements, labor_stations, how='inner', left_on=['latitude', 'longitude'], right_on=['latitude', 'longitude'])\n",
    "\n",
    "df = df.drop(columns=['latitude', 'longitude'])\n",
    "df = df[['location', 'warning', 'TEMP', 'PRES', 'PM2.5', 'NOx', 'PM10', 'C2H3NO5', 'CH4', 'Pb', 'NH3', 'SO2', 'O3', 'CO', 'PAHs', 'H2CO', 'CFCs']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af269b7a-0fe0-43fc-be2c-4addf151f57e",
   "metadata": {},
   "source": [
    "Prekodovanie textu lokácie na číselné hodnoty pre umožnenie spracovania ML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45ffb9e-c8cb-4fce-94dc-b0e1019562a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11939 entries, 0 to 11938\n",
      "Data columns (total 17 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   location  11939 non-null  object \n",
      " 1   warning   11891 non-null  float64\n",
      " 2   TEMP      11891 non-null  float64\n",
      " 3   PRES      11939 non-null  float64\n",
      " 4   PM2.5     11891 non-null  float64\n",
      " 5   NOx       11891 non-null  float64\n",
      " 6   PM10      11891 non-null  float64\n",
      " 7   C2H3NO5   11891 non-null  float64\n",
      " 8   CH4       11891 non-null  float64\n",
      " 9   Pb        11891 non-null  float64\n",
      " 10  NH3       11891 non-null  float64\n",
      " 11  SO2       11891 non-null  float64\n",
      " 12  O3        11891 non-null  float64\n",
      " 13  CO        11891 non-null  float64\n",
      " 14  PAHs      11891 non-null  float64\n",
      " 15  H2CO      11891 non-null  float64\n",
      " 16  CFCs      11891 non-null  float64\n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c29c6-7f8c-4695-9b9e-1260fe82777d",
   "metadata": {},
   "source": [
    "# Fáza 2 - Pipeline <a name=\"faza2\"></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23e5956d-81c3-47f1-b1bf-5766dab9aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_changed = df.copy() # zachovanie originálneho df pre potencionálne pororvnávanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673526fa-ba6a-43b8-934c-2dc0c7761cda",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6631d395-07df-4a3f-97ff-258095dbea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_columns(df):\n",
    "    return df.columns[df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6208f74c-dcb0-4758-b0d4-66f288d72b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(df):\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    corr_diff = df.corr() - df_original.corr()\n",
    "    sns.heatmap(corr_diff[abs(corr_diff) > 0.000099], ax=ax, annot=True, fmt=\".4f\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4bc417-e15f-4b8d-ab78-60a6a7c1bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_columns(df):\n",
    "    new_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col not in ['location', 'warning']:\n",
    "            new_cols.append(col)\n",
    "        \n",
    "    print(new_cols)\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2bc24d-b226-4f93-87fa-0db5b59b61f1",
   "metadata": {},
   "source": [
    "### Handle NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fddff0c9-2ab2-4f7f-98d2-be61a04b85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_drop(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        df = df.dropna().reset_index()\n",
    "        print(df.isnull().sum())\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e559fa2-ca09-4e1f-b1c5-a9d6abc09239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_mean(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        na_cols = df_columns(df)\n",
    "        imp_strategy = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        \n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "\n",
    "        df = df.dropna().reset_index()\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcf09ab-8465-4800-a05a-9d923f4d2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_median(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        na_cols = df_columns(df)\n",
    "        imp_strategy = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        \n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "\n",
    "        df = df.dropna().reset_index()\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c84cf6-b97e-4430-af08-7f27d602869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_knn(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        na_cols = df_columns(df)\n",
    "        imp_strategy = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "        \n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "\n",
    "        df = df.dropna().reset_index()\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d4bf6-d37d-4ad7-93ff-3896c90ac0fc",
   "metadata": {},
   "source": [
    "### Handle non numeric atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd463a6-f78f-45cf-a8a6-45e510b3308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleLocation(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def encodeLocation(self, df):\n",
    "        # prekodovanie textu locacie n číslo \n",
    "        ce_ordinal = ce.OrdinalEncoder(cols=['location'])\n",
    "        return ce_ordinal.fit_transform(df)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.encodeLocation(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e031-0d32-4ad2-9cde-9c2b8acd598e",
   "metadata": {},
   "source": [
    "### Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f953d66b-08ba-44b0-929b-562e4572487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleOutliers_replace(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "       \n",
    "    def handleOutliers(self, df):\n",
    "        \n",
    "        for col in df_columns(df):  \n",
    "            \n",
    "            q05 = percentile(df[col], 5)\n",
    "            q95 = percentile(df[col], 95)\n",
    "\n",
    "            df[col] = np.where(df[col] < q05, q05, df[col])\n",
    "            df[col] = np.where(df[col] > q95, q95, df[col])\n",
    "            \n",
    "        return df\n",
    "         \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.handleOutliers(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2f63b-6842-457c-97ae-07b870997d05",
   "metadata": {},
   "source": [
    "### Handle Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aed1288-0d4b-46b9-ae13-243b9190995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_power(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "        new_df = pd.DataFrame(power.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c9cd9b4-8373-4ac3-ad88-309d619d6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_quant(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        quan = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "        new_df = pd.DataFrame(quan.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e1df721-35c2-4a2c-aee0-ad1003b83f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_scaleMM(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        norm_s = MinMaxScaler()\n",
    "        new_df = pd.DataFrame(norm_s.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "211c4d4b-ad7e-450c-bce0-3b81bf937ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_scaleS(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        stan_s = StandardScaler()\n",
    "        new_df = pd.DataFrame(stan_s.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85441ca7-1374-43a0-b847-707709c4de33",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f36274ca-2e92-4834-8d9e-5a3ce2b13c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):  \n",
    "        df = X\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop(['warning'], axis=1), df['warning'], test_size=0.33)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c9478-96c7-42ca-8e23-7ddca839b854",
   "metadata": {},
   "source": [
    "### Handle Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b39b20-eb9a-4e9e-8844-c099f77e4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarianceThreshold_do(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        sel = VarianceThreshold(.8 * (1 - .8))\n",
    "        colsVT = sel.fit_transform(df)\n",
    "                        \n",
    "        if (df.shape[1] == colsVT[0].size):\n",
    "            print('VarianceThreshold: Všetky dáta sú užitočné')\n",
    "            \n",
    "        elif (colsVT[0].size < df.shape[1]):\n",
    "            print('VarianceThreshold: Máme aj neužitočné dáta')\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acfc6f48-ea4b-44e6-abf6-d29109dd4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_KBest_mutual_info_regression(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectKBest(mutual_info_regression, k='all')\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bba8bd0f-12c1-43b6-8396-502646fc4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_KBest_f_regression(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectKBest(f_regression, k='all')\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "225f7269-765a-4460-b52a-748515842b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_Percentile_f_classif(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectPercentile(f_classif, percentile=100)\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d67a56b-e55f-4d38-a4ff-b355a18b4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_Percentile_f_regression(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectPercentile(f_regression, percentile=100)\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd88076-6439-46a4-8613-3d59f909303a",
   "metadata": {},
   "source": [
    "## 2.4.2. Pipeline <a name=\"2.4.2.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e683c2",
   "metadata": {},
   "source": [
    "### Pipeline č. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d328942-a0fe-4626-986e-eb1a0433658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipelineGenerator():\n",
    "    \n",
    "    pipeline =  Pipeline([\n",
    "        ('HandleNaNs', HandleNaNs_drop()),\n",
    "        ('HandleLocation', HandleLocation()),\n",
    "        ('HandleOutliers', HandleOutliers_replace()),\n",
    "        ('HandleTransformations', HandleTransformations_power()),\n",
    "        ('HandleSelection', VarianceThreshold_do()),\n",
    "        ('Split', Split()),\n",
    "        ('handleSelection2', Selection_Percentile_f_regression()),\n",
    "        \n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "faa6769b-9bb0-4ef2-afd9-0cc525a6d556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index       0\n",
      "location    0\n",
      "warning     0\n",
      "TEMP        0\n",
      "PRES        0\n",
      "PM2.5       0\n",
      "NOx         0\n",
      "PM10        0\n",
      "C2H3NO5     0\n",
      "CH4         0\n",
      "Pb          0\n",
      "NH3         0\n",
      "SO2         0\n",
      "O3          0\n",
      "CO          0\n",
      "PAHs        0\n",
      "H2CO        0\n",
      "CFCs        0\n",
      "dtype: int64\n",
      "['index', 'TEMP', 'PRES', 'PM2.5', 'NOx', 'PM10', 'C2H3NO5', 'CH4', 'Pb', 'NH3', 'SO2', 'O3', 'CO', 'PAHs', 'H2CO', 'CFCs']\n",
      "VarianceThreshold: Všetky dáta sú užitočné\n"
     ]
    }
   ],
   "source": [
    "pipeline1 = pipelineGenerator()\n",
    "X_train, X_test, y_train, y_test = pipeline1.fit_transform(df_not_changed.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49a696",
   "metadata": {},
   "source": [
    "### Pipeline č. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33929824-a8b4-4902-9a33-474610079b13",
   "metadata": {},
   "source": [
    "## Export do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "860c8b15-16a0-4511-8e68-80a86fea9a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def toFiles(X_train, X_test, y_train, y_test):\n",
    "    X_train.to_csv('X_train.csv', sep=';')\n",
    "    X_test.to_csv('X_test.csv', sep=';')\n",
    "    y_train.to_csv('y_train.csv', sep=';')\n",
    "    y_test.to_csv('y_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14201eb1-2169-4851-963f-6ca83db0f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toFiles(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa710d44-226e-4346-9b74-75106e3abd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7529\n",
      "7529\n",
      "3709\n",
      "3709\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90496cb8-fba5-4bd5-9200-c4af46141649",
   "metadata": {},
   "source": [
    "# Fáza 3 - Strojové učenie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b103f36-31a3-468a-894e-ed208e3e0d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(predicted_train, predicted_test, y_train, y_test):\n",
    "    \n",
    "    print(\"Predicting for train dataset:\")\n",
    "    print(classification_report(y_train, predicted_train))\n",
    "\n",
    "    print(\"Predicting for test dataset:\")\n",
    "    print(classification_report(y_test, predicted_test))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be82e7e-5cdb-4e0e-9d3d-f4d4dee70226",
   "metadata": {},
   "source": [
    "## Jednoduchý klasifikátor na základe závislosti v dátach (5b)\n",
    "* Naimplementujte OneR algorithm (iné mená: OneRule or 1R), ktorý je jednoduchý klasifikátor tzv. rozhodnutie na základe jedného atribútu. Môžete implementovať aj komplikovanejšie t.j. rozhodnutie na základe kombinácie atribútov.\n",
    "* Algoritmus by mal byť realizovaný na základe závislostí v dátach. Vyhodnoťte klasifikátora pomocou metrík accuracy, precision a recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8b09a-cb78-431b-9c32-0e4897956726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec6cc307-8779-49d1-b219-e640ace1246d",
   "metadata": {},
   "source": [
    "## Trénovanie a vyhodnotenie klasifikátorov strojového učenia \n",
    "* Na trénovanie využite minimálne jeden stromový algoritmus strojového učenia v scikit-learn.\n",
    "* Vizualizujte natrénované pravidlá.\n",
    "* Vyhodnoťte natrénované modely pomocou metrík accuracy, precision a recall\n",
    "* Porovnajte ašpoň jeden natrénovaný klasifikátor v scikit-learn s jednoduchým klasifikátorom z prvého kroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9843431f-43a7-40cd-a3cf-cf604b9428f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.2.1 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05d11285-dd95-4d54-99f2-053b27872dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTreeDriver(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    cls = DecisionTreeClassifier(max_depth=None, random_state=1)\n",
    "    cls.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_train = cls.predict(X_train)\n",
    "    predicted_test = cls.predict(X_test)\n",
    "    \n",
    "    print_results(predicted_train, predicted_test, y_train, y_test)\n",
    "    \n",
    "    return cls, predicted_train, predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e710b84-20b7-44fa-9c68-6ed8bdead31f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdecisionTreeDriver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [32], line 3\u001b[0m, in \u001b[0;36mdecisionTreeDriver\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecisionTreeDriver\u001b[39m(X_train, X_test, y_train, y_test):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m     predicted_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "decisionTreeDriver(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1f2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
