{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03800150-2d8f-4045-a693-1d21b59e804d",
   "metadata": {},
   "source": [
    "# IAU projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b4c4ea-39f7-4166-95e3-e8f91e4d949f",
   "metadata": {},
   "source": [
    "> Rovnakým podieľom práce vypracovali: <br>\n",
    "> Roman Bitarovský, Emma Macháčová"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500c8350",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pause' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpause\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pause' is not defined"
     ]
    }
   ],
   "source": [
    "pause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391929a1",
   "metadata": {},
   "source": [
    "## Table of contents <a name=\"obsah\"></a>\n",
    "* [Zadanie](#zadanie)\n",
    "    * [Slovníček](#slovnicek)\n",
    "   \n",
    "* [Data init (Fáza 1)](#dataInit)\n",
    "* [Fáza 2](#faza2)\n",
    "    * [2.1. Integrácia a čistenie dát](#2.1.)\n",
    "        * [2.1.1. Replacing NaNs](#2.1.1.)\n",
    "            * [2.1.1.1. Replacing NaNs - Method 1: Drop nans](#2.1.1.a)\n",
    "            * [2.1.1.2. Replacing NaNs - Method 2: Replace with Mean](#2.1.1.b)\n",
    "            * [2.1.1.3. Replacing NaNs - Method 3: Replace with Median](#2.1.1.c)\n",
    "            * [2.1.1.4. Replacing NaNs - Method 4: Replace with kNN](#2.1.1.d)\n",
    "        * [2.1.2. Deleting Outliers Values](#2.1.2.)\n",
    "    * [2.2. Realizácia predspracovania dát](#2.2.)  \n",
    "        * [2.2.1. Transforovanie a škálovanie dát](#2.2.1.)\n",
    "        * [2.2.2. Rozdelenie dát](#2.2.2.)\n",
    "        * [2.2.3. Zhodnotenie ](#2.2.3.)\n",
    "    * [2.3. Výber atribútov pre strojové učenie](#2.3.)  \n",
    "        * [2.3.1. Variance Threshold ](#2.3.1.)\n",
    "        * [2.3.2. SelectKBest](#2.3.2.)\n",
    "        * [2.3.3 SelectPercentile](#2.3.3.)\n",
    "        * [2.3.4. Záver výberov](#2.3.4.)\n",
    "    * [2.4. Replikovateľnosť predspracovania](#2.4.)  \n",
    "        * [2.4.1. Code improvements](#2.4.1.)\n",
    "        * [2.4.2. Pipeline](#2.4.2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb7b2a",
   "metadata": {},
   "source": [
    "# Zadanie <a name=\"zadanie\"></a>\n",
    "Znečistenie ovzdušia spôsobuje vážne dýchacie a srdcové ochorenia, ktoré môžu byť smrteľné. Najčastejšie sú postihnuté deti, čo vedie k zápalu pľúc a problémom s dýchaním vrátane astmy. Kyslé dažde, ničenie ozónovej vrstvy a globálne otepľovanie sú niektoré z nepriaznivých dôsledkov. Dátová sada pre Vás (World's Air Pollution: Real-time Air Quality Index https://waqi.info/) predstavuje záznamy jednotlivých meraní kvality ovzdušia ako kombinácia mnohých faktorov bez časovej následnosti. V záznamoch je závislá premenná s menom “warning” indikujúca alarmujúci stav kvality ovzdušia. Vo veľkých mestách ako napr. Peking (angl. Beijing, hlavné mesto Číny s viac ako 21 miliónov ľudí) sa pri varovaní spustí opatrenie ako obmedzenie pohybov áut a ľudí v meste alebo umelý dážď až pokiaľ kvalita vzduchu sa nevráti do normu.\n",
    "\n",
    "* Úlohou je predikovať závislé hodnoty premennej “warning” pomocou metód strojového učenia.\n",
    "* Pritom sa treba vysporiadať s viacerými problémami, ktoré sa v dátach nachádzajú ako formáty dát, chýbajúce, vychýlené hodnoty a pod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca932d7e",
   "metadata": {},
   "source": [
    "## Slovníček  <a name=\"slovnicek\"></a>\n",
    "<details>\n",
    "    <summary>Zobraziť</summary>\n",
    "    \n",
    "    PM2.5 - Particulate Matter (µg/m3) \n",
    "    PM10 - Particulate Matter (µg/m3) \n",
    "    NOx - Nitrogen Oxides (µg/m3)\n",
    "    NO2 - Nitrogen Dioxide (µg/m3)\n",
    "    SO2 - Sulfur Dioxide  (µg/m3)\n",
    "    CO - Carbon Monoxide emissions  (µg/m3)\n",
    "    CO2 - Carbon Dioxide  (µg/m3)\n",
    "    PAHs - Polycyclic Aromatic Hydrocarbons  (µg/m3)\n",
    "    NH3 - Ammonia trace  (µg/m3)\n",
    "    Pb - Lead  (µg/m3)\n",
    "    TEMP - Temperature (degree Celsius)\n",
    "    DEWP - Dew point temperature (degree Celsius)\n",
    "    PRES - Pressure (hPa, <100, 1050>)\n",
    "    RAIN - Rain (mm)\n",
    "    WSPM - Wind Speed (m/s)\n",
    "    WD - Wind Direction\n",
    "    VOC - Volatile Organic Compounds\n",
    "    CFCs - Chlorofluorocarbons\n",
    "    C2H3NO5 - Peroxyacetyl nitrate\n",
    "    H2CO - Plywood emit formaldehyde\n",
    "    GSTM1 - Glutathione-S transferase M1\n",
    "    1-OHP - 1-hydroxypyrene\n",
    "    2-OHF - 2-hydroxyfluorene\n",
    "    2-OHNa - 2-hydroxynaphthalene\n",
    "    N2 - Nitrogen\n",
    "    O2 - Oxygen\n",
    "    O3 - Ozone\n",
    "    Ar - Argon\n",
    "    Ne - Neon\n",
    "    CH4 - Methane\n",
    "    He - Helium\n",
    "    Kr - Krypton\n",
    "    I2 - Iodine\n",
    "    H2 - Hydrogen\n",
    "    Xe - Xenon\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8344e4ef-bf7a-4a03-9614-b6f3f23fa673",
   "metadata": {},
   "source": [
    "# Data init <a name=\"dataInit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3283a09-1bbb-4c16-9a19-e162077e5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.stats as sm_stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from numpy import percentile\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, SelectFromModel\n",
    "from sklearn.feature_selection import mutual_info_regression, chi2, f_regression, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d4502-5363-424b-bc0b-7defa57eda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_measurements = pd.read_csv('../081/measurements.csv', sep='\\t')\n",
    "labor_stations = pd.read_csv('../081/stations.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77e3ec-c960-411d-846b-20b5e3ae3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labor_stations[\"QoS\"].replace({\"acceptable\": \"accep\", \"maitennce\": \"maintenance\"}, inplace=True)\n",
    "labor_stations['revision'] = pd.to_datetime(labor_stations['revision'], utc=False)\n",
    "\n",
    "labor_measurements.replace('', np.nan, inplace=True)\n",
    "labor_stations.replace('', np.nan, inplace=True)\n",
    "\n",
    "labor_measurements = labor_measurements.drop_duplicates()\n",
    "labor_stations = labor_stations.drop_duplicates()\n",
    "\n",
    "# merge preprocesing\n",
    "labor_stations = labor_stations.drop(columns=['revision', 'code', 'QoS'])\n",
    "labor_stations = labor_stations.drop_duplicates()\n",
    "\n",
    "# Table merge\n",
    "df = pd.merge(labor_measurements, labor_stations, how='inner', left_on=['latitude', 'longitude'], right_on=['latitude', 'longitude'])\n",
    "\n",
    "df = df.drop(columns=['latitude', 'longitude'])\n",
    "df = df[['location', 'warning', 'TEMP', 'PRES', 'PM2.5', 'NOx', 'PM10', 'C2H3NO5', 'CH4', 'Pb', 'NH3', 'SO2', 'O3', 'CO', 'PAHs', 'H2CO', 'CFCs']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ffb9e-c8cb-4fce-94dc-b0e1019562a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c29c6-7f8c-4695-9b9e-1260fe82777d",
   "metadata": {},
   "source": [
    "# Fáza 2 Predspracovanie údajov <a name=\"faza2\"></a> \n",
    " \n",
    "# 2.1 Integrácia a čistenie dát (5b) <a name=\"2.1.\"></a>\n",
    "Transformujte dáta na vhodný formát pre strojové učenie t.j. jedno pozorovanie musí byť opísané jedným riadkom a každý atribút musí byť v numerickom formáte. \n",
    "* Pri riešení chýbajúcich hodnôt (missing values) vyskúšajte rôzne stratégie ako napr.\n",
    "    * odstránenie pozorovaní s chýbajúcimi údajmi\n",
    "    * nahradenie chýbajúcej hodnoty mediánom, priemerom, pomerom (ku korelovanému atribútu), alebo pomocou lineárnej regresie resp. kNN\n",
    "* Podobne postupujte aj pri riešení vychýlených hodnôt (outlier detection):\n",
    "    * odstránenie vychýlených (odľahlých) pozorovaní\n",
    "    * nahradenie vychýlenej hodnoty hraničnými hodnotami rozdelenia (5% resp. 95%)\n",
    "  \n",
    "<b>Go to:</b>  \n",
    "* [Naspäť na Obsah](#obsah)\n",
    "* [Replacing NaNs - Method 1: Drop nans](#2.1.1.a)\n",
    "* [Replacing NaNs - Method 2: Replace with Mean](#2.1.1.b)\n",
    "* [Replacing NaNs - Method 3: Replace with Median](#2.1.1.c)\n",
    "* [Replacing NaNs - Method 4: Replace with kNN](#2.1.1.d)\n",
    "* [Deleting Outliers Values](#2.1.2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5956d-81c3-47f1-b1bf-5766dab9aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_changed = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152fcea4-5c44-4e01-9a8b-7774d5958daa",
   "metadata": {},
   "source": [
    "## 2.1.1. Replacing NaNs <a name=\"2.1.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4357159-63ef-47f4-b571-5991077a210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNaN(df_original, strategy):\n",
    "    df = df_original.copy()\n",
    "\n",
    "    na_cols = df.columns[df.isnull().any()].tolist()\n",
    "    \n",
    "    if strategy == 'kNN':\n",
    "        imp_strategy = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "    elif strategy == 'mean' or strategy == 'median':    \n",
    "        imp_strategy = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "        \n",
    "    elif strategy == 'drop_na':\n",
    "        df = df.dropna()\n",
    "        \n",
    "    if strategy != 'drop_na':\n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "        \n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    corr_diff = df.corr() - df_original.corr()\n",
    "    sns.heatmap(corr_diff[abs(corr_diff) > 0.000099], ax=ax, annot=True, fmt=\".4f\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5502a39-60b0-4053-a2d1-60703e375a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prekodovanie textu locacie n číslo \n",
    "ce_ordinal = ce.OrdinalEncoder(cols=['location'])\n",
    "df_ml = ce_ordinal.fit_transform(df)\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566e7c3-f3d7-4613-b9da-e87c6579ada2",
   "metadata": {},
   "source": [
    "### Replacing NaNs - Method 1: Drop nans <a name=\"2.1.1.a\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5961099-2c10-4a3d-b430-890607ceb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_dropedNa = replaceNaN(df_ml, 'drop_na')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090288e5-2157-4747-a7d6-5b629737da8c",
   "metadata": {},
   "source": [
    "### Replacing NaNs - Method 2: Replace with Mean <a name=\"2.1.1.b\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a29726-4db4-4861-ab27-8de3fb79e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_na_mean = replaceNaN(df_ml, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336abf9-8cbe-45f0-8569-786cfff15fa1",
   "metadata": {},
   "source": [
    "### Replacing NaNs - Method 3: Replace with Median <a name=\"2.1.1.c\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa7943-0523-44c4-9257-be9d8f84dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_na_median = replaceNaN(df_ml, 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69693b01-3825-434c-bc6e-54b51128f669",
   "metadata": {},
   "source": [
    "### Replacing NaNs - Method 4: Replace with kNN <a name=\"2.1.1.d\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2da80-506a-4f53-8cbf-92d47dbd918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_na_knn = replaceNaN(df_ml, 'kNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e07cdd-62d9-42a4-8eb5-05c3ea8b21b4",
   "metadata": {},
   "source": [
    "## 2.1.2. Deleting Outliers Values <a name=\"2.1.2.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209f3f7-dd50-459d-a04b-5c199a056ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_na_knn.plot(kind='box', subplots=True, layout=(7, 3), sharex=False, sharey=False, figsize=(20, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c6b9e4-e6b2-4035-bf17-f11e14eb75ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers_limit_low = 0\n",
    "outliers_limit_up = 0\n",
    "def identify_outliers(df):\n",
    "    \n",
    "    Qa = df.quantile(0.05)\n",
    "    Qb = df.quantile(0.95)\n",
    "    IQR = Qb - Qa\n",
    "    \n",
    "    global outliers_limit_low\n",
    "    outliers_limit_low = (Qa - 1.5 * IQR)\n",
    "    global outliers_limit_up \n",
    "    outliers_limit_up = (Qb + 1.5 * IQR)\n",
    "    \n",
    "    return ((df < outliers_limit_low) | (df > outliers_limit_up)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6d878-1fdd-493c-94ae-efac06930f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers(df_ml_na_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fcffc6-059b-42d6-afae-c5e22d98b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_limit_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9e79d-2c05-4e95-910e-966268a8d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_limit_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5273c05-0612-4d1a-9e63-9bd8bf3aac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(df_original):\n",
    "    df = df_original.copy()\n",
    "    \n",
    "    for col in df.columns:\n",
    "\n",
    "        low = outliers_limit_low[col]\n",
    "        up = outliers_limit_up[col]\n",
    "        df[col] = np.where(df[col] < low, low, df[col])\n",
    "        df[col] = np.where(df[col] > up, up, df[col])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ba015-3d0d-43ec-a898-f9b60cf2f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_na_knn_notOutliers = replace_outliers(df_ml_na_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063b72a-2b88-4423-a46a-d516b15111be",
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers(df_ml_na_knn_notOutliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_na_knn.plot(kind='box', subplots=True, layout=(1, 17), sharex=False, sharey=False, figsize=(20, 5))\n",
    "plt.title('Pred odstránením outlierov')\n",
    "df_ml_na_knn_notOutliers.plot(kind='box', subplots=True, layout=(1, 17), sharex=False, sharey=False, figsize=(20, 5))\n",
    "plt.title('Po odstránení outlierov')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390fb63-e866-439e-8afd-8c454f8016fb",
   "metadata": {},
   "source": [
    "# 2.2. Realizácia predspracovania dát (5b). <a name=\"2.2.\"></a>\n",
    "* Transformované dáta pre strojové učenie si rozdeľuje na trénovaciu a testovaciu množinu podľa vami preddefinovaným pomerom. Naďalej pracujte len s trénovacím datasetom.\n",
    "* Transformujte atribútov dát pre strojové učenie podľa dostupných techník (minimálne 2 techniky) ako scaling, transformers a ďalšie.\n",
    "* Zdôvodnite Vašu voľby/rozhodnutie pre realizáciu (t.j. zdokumentovanie)\n",
    "\n",
    "<b>Go to:</b>  \n",
    "* [Naspäť na Obsah](#obsah)\n",
    "* [Transforovanie a škálovanie dát](#2.2.1.)\n",
    "* [Rozdelenie dát](#2.2.2.)\n",
    "* [Zhodnotenie ](#2.2.3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00fde1-744b-452e-b334-40e656127501",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ml_na_knn_notOutliers.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964c5cac-31b5-4ad1-9975-5af25080a91c",
   "metadata": {},
   "source": [
    "## 2.2.1. Transforovanie a škálovanie dát <a name=\"2.2.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beec1824-5a9b-4bb5-92c7-751eb0be343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "quan = QuantileTransformer(n_quantiles=20, random_state=0)\n",
    "stan_s = StandardScaler()\n",
    "norm_s = MinMaxScaler()\n",
    "\n",
    "m_col = [\n",
    "    'TEMP', 'TEMP', \n",
    "    'PRES', 'PRES',\n",
    "    'PM2.5', 'PM2.5', \n",
    "    'NOx', 'NOx', \n",
    "    'PM10','PM10', \n",
    "    'C2H3NO5', 'C2H3NO5', \n",
    "    'CH4', 'CH4',\n",
    "    'Pb', 'Pb',          \n",
    "    'NH3', 'NH3', \n",
    "    'SO2', 'SO2',\n",
    "    'O3', 'O3',\n",
    "    'CO', 'CO',\n",
    "    'PAHs', 'PAHs', \n",
    "    'H2CO', 'H2CO',\n",
    "    'CFCs', 'CFCs'\n",
    "]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,120))\n",
    "\n",
    "for num, col_name in enumerate(m_col):\n",
    "    \n",
    "    plt.subplot(16, 2, num+1)\n",
    "    plt.hist(df[col_name], bins=25)\n",
    "    \n",
    "    if num % 2 == 0:\n",
    "        plt.title(col_name + ' - Transformacia')\n",
    "        pow_trans = power.fit_transform(df[[col_name]])\n",
    "        plt.hist(pow_trans, bins=25)\n",
    "        q_trans = quan.fit_transform(df[[col_name]])\n",
    "\n",
    "        plt.hist(q_trans, bins=25)\n",
    "        plt.grid()\n",
    "        plt.legend(['origin', 'power_t', 'quan_t'])\n",
    "\n",
    "    \n",
    "    else:\n",
    "        plt.title(col_name + ' - Skalovanie')\n",
    "        s_scaled = stan_s.fit_transform(df[[col_name]])\n",
    "        plt.hist(s_scaled, bins=25)\n",
    "        n_scaled = norm_s.fit_transform(df[[col_name]])\n",
    "\n",
    "        plt.hist(n_scaled, bins=25)\n",
    "        plt.grid()\n",
    "        plt.legend(['origin', 'stan_s', 'norm_s'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb83ffe-ec51-48cd-b51f-3b6e6b3ff47a",
   "metadata": {},
   "source": [
    "yeo-johnson sme vybrali preto lebo Box-cox nepodporuje transformáciu záporných hodnôt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8cbe61-bf5a-4c49-8480-3331c0d6c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TODO napísať vyhodnotenie pre tieto obrázky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890e9cd-b9ad-433a-ac7c-bd598e946a8d",
   "metadata": {},
   "source": [
    "## 2.2.2. Rozdelenie dát <a name=\"2.2.2.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73588ad1-c962-4575-ba74-e17d15815340",
   "metadata": {},
   "source": [
    "Dataset rozdelíme v pomere 1/3 pre testovaciu množinu a 2/3 pre trénovaciu množinu \n",
    "pre indikátor (y) a pre všetky ostatné atribúty (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713c771-c59f-4949-ae72-aac5fde4434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['warning'], axis=1), df['warning'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fa95c-35e6-4dbe-9c80-57452ed365e6",
   "metadata": {},
   "source": [
    "## 2.2.3. Zhodnotenie <a name=\"2.2.3.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea1841-50f4-4fdb-8a87-fe6d808016d5",
   "metadata": {},
   "source": [
    "@TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465c0cd4-a4ac-40d5-b455-9f04bb91b71a",
   "metadata": {},
   "source": [
    "# 2.3. Výber atribútov pre strojové učenie (5b) <a name=\"2.3.\"></a>\n",
    "* Zistite ktoré atribúty (features) vo vašich dátach pre strojové učenie sú informatívne k atribútu “warning”. Zoradíte tie atribúty v poradí podľa dôležitosti. \n",
    "* Zdôvodnite Vašu voľby/rozhodnutie pre realizáciu (t.j. zdokumentovanie)\n",
    "\n",
    "<b>Go to:</b>  \n",
    "* [Naspäť na Obsah](#obsah)\n",
    "* [Variance Threshold ](#2.3.1.)\n",
    "* [SelectKBest](#2.3.2.)\n",
    "* [SelectPercentile](#2.3.3.)\n",
    "* [Záver výberov](#2.3.4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea6479-28b7-4336-b89f-8a32d3b6b00f",
   "metadata": {},
   "source": [
    "## 2.3.1. Variance Threshold <a name=\"2.3.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f03a1-d02e-4f4b-81ee-0cc0f7cedf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.copy()\n",
    "y = y_train.copy()\n",
    "print(X.columns)\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "colsVT = sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b026d0-331b-4e86-abeb-3369e9d4dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pôvodný počet stĺpcov: ', X.shape[1])\n",
    "if (X.shape[1] == colsVT[0].size):\n",
    "    print('Všetky dáta sú užitočné')\n",
    "elif (colsVT[0].size < X.shape[1]):\n",
    "    print('Máme aj neužitočné dáta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f36e28-f904-4baa-aa39-428438ab13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65161c1-6cdc-499e-942f-eca8e8e05800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderColumns(X, y, selectionType, selectionTypeCategory):\n",
    "    \n",
    "    if (selectionTypeCategory == 'SelectKBest'):\n",
    "        selector = SelectKBest(selectionType, k ='all')\n",
    "    \n",
    "    elif (selectionTypeCategory == 'SelectPercentile'):\n",
    "        selector = SelectPercentile(selectionType, percentile=100)\n",
    "    \n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    scores = selector.scores_\n",
    "    \n",
    "    col_names = X.columns[selector.get_support()]\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "        indices.append(x)\n",
    "    \n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e63555-1547-428f-8ed8-838ec51993c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3ed65-b383-4043-b3d2-31a3ae5d83e0",
   "metadata": {},
   "source": [
    "## 2.3.2. SelectKBest <a name=\"2.3.2.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4d916-bf6f-4278-b896-9656d6bedd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_funcs_list = [mutual_info_regression, f_regression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c0b90-f4e0-4d20-bbb7-763b86df88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in orders_funcs_list:\n",
    "    temp = orderColumns(X, y, i, 'SelectKBest')\n",
    "    list_of_list.append(temp)\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab0458-0296-4de4-b968-1ff4b7f21edb",
   "metadata": {},
   "source": [
    "## 2.3.3 SelectPercentile <a name=\"2.3.3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7545c-3762-4fbe-9c3b-3e270c746155",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_funcs_list = [f_classif, f_regression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b19a85-71d8-4d55-beca-f4ec95ef12f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in orders_funcs_list:\n",
    "    temp = orderColumns(X, y, i, 'SelectPercentile')\n",
    "    list_of_list.append(temp)\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9cb3cd-9182-4b76-85f8-2fffa593c9f3",
   "metadata": {},
   "source": [
    "### 2.3.4. Záver výberov <a name=\"2.3.4.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed560a1-79aa-42eb-baa5-7fc8a1b7110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderLists(X, list_of_list):\n",
    "    \n",
    "    x_columns = X.columns\n",
    "    x_weights = []\n",
    "    \n",
    "    for i in range(len(x_columns)):\n",
    "        x_weights.append(i)\n",
    "    \n",
    "    for lst in list_of_list:\n",
    "        for i in range(len(x_columns)):\n",
    "            x_weights[i] += lst.index(x_columns[i])  \n",
    "            \n",
    "    map_of_cols = []\n",
    "    for _, q in sorted(zip(x_weights, x_columns)):\n",
    "        map_of_cols.append(q)\n",
    "    \n",
    "    return map_of_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa0293-a8a1-4150-9552-6c508b2b17ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderLists(X, list_of_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbf90b-1320-4bb7-8075-153de772c444",
   "metadata": {},
   "source": [
    "#### Záver výberu atribútov pre strojové učenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfd2cf-8fd3-4878-a358-2b8a8be349f4",
   "metadata": {},
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eac7794-4b3c-4d61-b83e-dbf29c40afe3",
   "metadata": {},
   "source": [
    "# 2.4. Replikovateľnosť predspracovania (5b) <a name=\"2.4.\"></a>\n",
    "* Upravte váš kód realizujúci predspracovanie trénovacej množiny tak, aby ho bolo možné bez ďalších úprav znovupoužiť na predspracovanie testovacej množiny (pomocou funkcie/í)\n",
    "* Očakáva sa aj využitie možnosti sklearn.pipeline\n",
    "\n",
    "<b>Go to:</b>  \n",
    "* [Naspäť na Obsah](#obsah)\n",
    "* [Code improvements](#2.4.1.)\n",
    "* [Pipeline](#2.4.2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d764c63-36e8-4ddc-91a8-6f1979d573d1",
   "metadata": {},
   "source": [
    "## 2.4.1. Code improvements <a name=\"2.4.1.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673526fa-ba6a-43b8-934c-2dc0c7761cda",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631d395-07df-4a3f-97ff-258095dbea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_columns(df):\n",
    "    return df.columns[df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208f74c-dcb0-4758-b0d4-66f288d72b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(df):\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    corr_diff = df.corr() - df_original.corr()\n",
    "    sns.heatmap(corr_diff[abs(corr_diff) > 0.000099], ax=ax, annot=True, fmt=\".4f\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bc417-e15f-4b8d-ab78-60a6a7c1bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_columns(df):\n",
    "    new_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col not in ['location', 'warning']:\n",
    "            new_cols.append(col)\n",
    "        \n",
    "    print(new_cols)\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2bc24d-b226-4f93-87fa-0db5b59b61f1",
   "metadata": {},
   "source": [
    "### Handle NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddff0c9-2ab2-4f7f-98d2-be61a04b85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_drop(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        df = df.dropna()\n",
    "\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e559fa2-ca09-4e1f-b1c5-a9d6abc09239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_mean(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        na_cols = count_columns(df)\n",
    "        imp_strategy = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        \n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf09ab-8465-4800-a05a-9d923f4d2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_median(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        na_cols = count_columns(df)\n",
    "        imp_strategy = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        \n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c84cf6-b97e-4430-af08-7f27d602869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleNaNs_knn(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replaceNaN(self, df):\n",
    "        na_cols = count_columns(df)\n",
    "        imp_strategy = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "        \n",
    "        for col in na_cols:\n",
    "            df[col] = imp_strategy.fit_transform(df[[col]])\n",
    "\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.replaceNaN(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d4bf6-d37d-4ad7-93ff-3896c90ac0fc",
   "metadata": {},
   "source": [
    "### Handle non numeric atributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd463a6-f78f-45cf-a8a6-45e510b3308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleLocation(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def encodeLocation(self, df):\n",
    "        # prekodovanie textu locacie n číslo \n",
    "        ce_ordinal = ce.OrdinalEncoder(cols=['location'])\n",
    "        return ce_ordinal.fit_transform(df)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.encodeLocation(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e031-0d32-4ad2-9cde-9c2b8acd598e",
   "metadata": {},
   "source": [
    "### Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1bad0-d373-4b57-a1f4-975aaa0b85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleOutliers_drop(TransformerMixin):\n",
    "    \n",
    "    outliers_limit_low = 0\n",
    "    outliers_limit_up = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "         \n",
    "    def handleOutliers(self, df):\n",
    "        \n",
    "        for col in df_columns(df):\n",
    "            \n",
    "            q_low = percentile(df[col], 25), \n",
    "            q_up = percentile(df[col], 75)\n",
    "\n",
    "            offset = (q_up - q_low) * 1.5\n",
    "\n",
    "            limit_low = q_low - offset,\n",
    "            limit_up = q_up + offset\n",
    "            \n",
    "        return df[((df[col] >= limit_low) & (df[col] <= limit_up))] \n",
    "         \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.handleOutliers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953d66b-08ba-44b0-929b-562e4572487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleOutliers_replace(TransformerMixin):\n",
    "    \n",
    "    outliers_limit_low = 0\n",
    "    outliers_limit_up = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "       \n",
    "    def handleOutliers(self, df):\n",
    "        \n",
    "        for col in df_columns(df):  \n",
    "            \n",
    "            q05 = percentile(df[col], 5)\n",
    "            q95 = percentile(df[col], 95)\n",
    "\n",
    "            df[col] = np.where(df[col] < q05, q05, df[col])\n",
    "            df[col] = np.where(df[col] > q95, q95, df[col])\n",
    "            \n",
    "        return df\n",
    "         \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.handleOutliers(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2f63b-6842-457c-97ae-07b870997d05",
   "metadata": {},
   "source": [
    "### Handle Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed1288-0d4b-46b9-ae13-243b9190995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_power(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "        new_df = pd.DataFrame(power.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9cd9b4-8373-4ac3-ad88-309d619d6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_quant(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        quan = QuantileTransformer(n_quantiles=10, random_state=0)\n",
    "        new_df = pd.DataFrame(quan.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1df721-35c2-4a2c-aee0-ad1003b83f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_scaleMM(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        norm_s = MinMaxScaler()\n",
    "        new_df = pd.DataFrame(norm_s.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c4d4b-ad7e-450c-bce0-3b81bf937ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandleTransformations_scaleS(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X\n",
    "        stan_s = StandardScaler()\n",
    "        new_df = pd.DataFrame(stan_s.fit_transform(df), columns = df.columns)\n",
    "        new_df['location'] = df['location']\n",
    "        new_df['warning'] = df['warning']\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85441ca7-1374-43a0-b847-707709c4de33",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36274ca-2e92-4834-8d9e-5a3ce2b13c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):  \n",
    "        df = X\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop(['warning'], axis=1), df['warning'], test_size=0.33)\n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c9478-96c7-42ca-8e23-7ddca839b854",
   "metadata": {},
   "source": [
    "### Handle Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b39b20-eb9a-4e9e-8844-c099f77e4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VarianceThreshold_do(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "\n",
    "        sel = VarianceThreshold(.8 * (1 - .8))\n",
    "        colsVT = sel.fit_transform(df)\n",
    "                        \n",
    "        if (df.shape[1] == colsVT[0].size):\n",
    "            print('VarianceThreshold: Všetky dáta sú užitočné')\n",
    "            \n",
    "        elif (colsVT[0].size < df.shape[1]):\n",
    "            print('VarianceThreshold: Máme aj neužitočné dáta')\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc6f48-ea4b-44e6-abf6-d29109dd4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_KBest_mutual_info_regression(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectKBest(mutual_info_regression, k='all')\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8bd0f-12c1-43b6-8396-502646fc4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_KBest_f_regression(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectKBest(f_regression, k='all')\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f7269-765a-4460-b52a-748515842b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_Percentile_f_classif(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectPercentile(f_classif, percentile=100)\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67a56b-e55f-4d38-a4ff-b355a18b4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selection_Percentile_f_regression(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def orderColumns(self, tuple_of_df):\n",
    "        X_train, X_test, y_train, y_test = tuple_of_df[0], tuple_of_df[1], tuple_of_df[2], tuple_of_df[3]\n",
    "                \n",
    "        selector = SelectPercentile(f_regression, percentile=100)\n",
    "        \n",
    "        selected = selector.fit_transform(X_train, y_train)\n",
    "        \n",
    "        scores = selector.scores_\n",
    "        \n",
    "        col_names = X_train.columns[selector.get_support()]\n",
    "\n",
    "        indices = []\n",
    "        for _, x in sorted(zip(scores, col_names), reverse=True):\n",
    "            indices.append(x)\n",
    "\n",
    "        X_train.columns = indices\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "    def fit(self, tuple_of_df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, tuple_of_df):\n",
    "        return self.orderColumns(tuple_of_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd88076-6439-46a4-8613-3d59f909303a",
   "metadata": {},
   "source": [
    "## 2.4.2. Pipeline <a name=\"2.4.2.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d328942-a0fe-4626-986e-eb1a0433658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipelineGenerator():\n",
    "    \n",
    "    pipeline =  Pipeline([\n",
    "        ('HandleNaNs', HandleNaNs_knn()),\n",
    "        ('HandleLocation', HandleLocation()),\n",
    "        ('HandleOutliers', HandleOutliers_replace()),\n",
    "        ('HandleTransformations', HandleTransformations_power()),\n",
    "        ('HandleSelection', VarianceThreshold_do()),\n",
    "        ('Split', Split()),\n",
    "        ('handleSelection2', Selection_Percentile_f_regression()),\n",
    "        \n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6769b-9bb0-4ef2-afd9-0cc525a6d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = pipelineGenerator()\n",
    "X_train, X_test, y_train, y_test = pipeline1.fit_transform(df_not_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27365f9f-b022-4976-abf4-f0414115b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6953f-e6a0-4216-a2e0-785cce171fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacba3e0-a16d-41b3-88bc-46ea329b5f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef479d7e-e523-4ec0-a150-e423873e4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf3105-4f7b-4a2c-8430-1d4c0ff87cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
